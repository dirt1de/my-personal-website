---
title: The Office IMDb rating analysis
author: Xuxin Zhang
date: '2020-09-13'
slug: the-office-imdb-rating-analysis
categories:
  - R project
tags:
  - sentiment analysis
  - text mining
  - tidymodel
  - machine learning
subtitle: ''
summary: ''
authors: []
lastmod: '2020-09-13T11:15:52+08:00'
featured: no
image:
  caption: ''
  focal_point: ''
  preview_only: yes
projects: []
---


In this project, we would conduct data analysis on TV series "The Office" which is one of my favorite TV series of all time. Trust me, you either hate it or you would really love it. Two datasets would be focused on: one containing the rating of each episode of the 9 seasons; the other data contains 
```{r, message=FALSE, warning=FALSE}
library(tidyverse)
library(tidytext)
library(schrute)
library(ggridges)
library(plotly)
library(tidymodels)

theme_set(theme_light())

office_script<-schrute::theoffice

ratings_raw <- readr::read_csv("https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2020/2020-03-17/office_ratings.csv")
```

## 2. Preliminary data analysis
### 2.1 Season and episode analysis

```{r}
ratings_raw%>%mutate(total_ep = row_number())%>%
  ggplot(aes(x = total_ep, y = imdb_rating))+
  geom_point(aes(color = as.factor(season)))+
  geom_path(aes(color = as.factor(season)))+
  geom_text(aes(label= title),hjust = 1,check_overlap = TRUE)+
  theme(legend.position = "null")+expand_limits(x = -20)+
  labs(x = "Episode number", y = "IMDb rating", title = "How the rating of each epsiode changes over time")+geom_smooth()
```

From this graph, we see that the average rating first goes up, then goes down. 

```{r}
ratings_raw%>%
  ggplot(aes(y = as.factor(season), 
             x = imdb_rating,
             fill = as.factor(season),
             group = as.factor(season)))+
  geom_density_ridges(alpha = 0.5, show.legend = FALSE)+
  expand_limits(y = 10.7)+
  labs(x = "IMDb rating", y = "Season number", title = "IMDb rating distribution for each season")
```

Now we can conduct a sentiment analysis for each of episode. 
```{r}
episode_sent<-office_script%>%
  select(season,episode, episode_name,character,text)%>%
  unnest_tokens(word,text)%>%anti_join(stop_words)%>%
  inner_join(get_sentiments("afinn"))%>%group_by(season,episode, episode_name)%>%
  summarise(sentiment = sum(value))%>%ungroup()%>%
  transmute(total_ep = row_number(),episode_name, sentiment,season)

episode_sent%>%
  ggplot(aes(x = total_ep, y = sentiment))+
  geom_point(aes(color = as.factor(season)))+
  geom_path(aes(color = as.factor(season)))+
  geom_text(aes(label= episode_name),hjust = 1,check_overlap = TRUE)+
  theme(legend.position = "null")+expand_limits(x = -20)+
  labs(x = "Episode number", y = "Sentiment level", title = "How the sentiment level of each epsiode changes over time")+geom_smooth()
  
```


```{r}
episode_sent%>%
  ggplot(aes(y = as.factor(season), 
             x = sentiment,
             fill = as.factor(season),
             group = as.factor(season)))+
  geom_density_ridges(alpha = 0.5, show.legend = FALSE)+
  expand_limits(y = 10.7)+
  labs(x = "Sentiment level", y = "Season number", title = "Sentiment level distribution for each season")
```

Then a natural question to ask is that if there is a relationship between the rating and sentiment level. 

```{r,warning=FALSE}
library(ggrepel)
ratings_raw%>%mutate(total_ep = row_number())%>%
  left_join(episode_sent)%>%
  ggplot(aes(x = sentiment, y = imdb_rating ))+
  geom_point(aes(color = as.factor(season)))+
  geom_smooth()+labs(x = "Sentiment level", y = "IMDb rating", title = "The relationship between the sentiment level and the IMDb rating of an episode", color = "Season")
```

```{r}
ratings_raw%>%mutate(total_ep = row_number())%>%
  left_join(episode_sent)%>%
  ggplot(aes(x = sentiment, y = imdb_rating,color = as.factor(season) ))+
  geom_point(show.legend = FALSE)+geom_smooth()+facet_wrap(~season)+labs(x = "Sentiment level", y = "IMDb rating", title = "The relationship between the sentiment level and the IMDb rating of an episode")+theme(legend.position = "null")
```

### 2.2 Character analysis

Based on the follow graph, we can see that Michael, Jim, Dwight, and Pam take the top 4 people with the most lines. The first place is later overthrowned by Andy and then later finally by Dwight. 

```{r}
library(tidytext)
office_script%>%count(season = as.factor(season), character)%>%
  group_by(season)%>%top_n(10)%>%
  ggplot(aes(x = n, y = reorder_within(character, n, season), fill = character))+
  geom_col()+scale_y_reordered()+facet_wrap(~season,scales = "free_y")+theme(legend.position = "null")
```


```{r}
top_character<-office_script%>%count(character,sort = TRUE)%>%top_n(12)%>%pull(character)

ggplotly(office_script%>%count(season, character)%>%
    filter(character%in%top_character)%>%
    ggplot(aes(x = season, y = n, color = character))+geom_point()+
    geom_path()+scale_y_log10()+scale_x_continuous(breaks = 1:9))
```


Text mining 
```{r}

office_script%>%
  select(season,episode, episode_name,character,text)%>%
  unnest_tokens(word,text)%>%anti_join(stop_words)%>%
  count(character,word)%>%filter(character%in%top_character)%>%
  bind_tf_idf(word,character,n)%>%
  group_by(character)%>%top_n(10)%>%ggplot(aes(x = tf_idf, y = reorder_within(word, tf_idf, character), fill = character))+geom_col(show.legend = FALSE)+facet_wrap(~character, scales = "free_y")+scale_y_reordered()
```


```{r}
character_season_line<-office_script%>%count(season, character)%>%
    filter(character%in%top_character)

ggplotly(office_script%>%
  select(season,episode, episode_name,character,text)%>%
  unnest_tokens(word,text)%>%anti_join(stop_words)%>%
  inner_join(get_sentiments("afinn"))%>%group_by(season,character)%>%
  summarise(sentiment = sum(value))%>%filter(character%in%top_character)%>%
  left_join(character_season_line)%>%mutate(av_sent = sentiment/n)%>%
  ggplot(aes(x = season, y = av_sent, color = character))+geom_point()+geom_path())
```

Modeling

```{r}
remove_regex <- "[:punct:]|[:digit:]|parts |part |the |and"

office_ratings <- ratings_raw %>%
  transmute(
    episode_name = str_to_lower(title),
    episode_name = str_remove_all(episode_name, remove_regex),
    episode_name = str_trim(episode_name),
    imdb_rating
  )

office_info <- schrute::theoffice %>%
  mutate(
    season = as.numeric(season),
    episode = as.numeric(episode),
    episode_name = str_to_lower(episode_name),
    episode_name = str_remove_all(episode_name, remove_regex),
    episode_name = str_trim(episode_name)
  ) %>%
  select(season, episode, episode_name, director, writer, character)
```

```{r}
actors<-office_info%>%count(episode_name, character)%>%
    add_count(character)%>%
    filter(nn >800)%>%
    select(-nn)%>%
    pivot_wider(names_from = character, values_from = n, values_fill = 0)

actors
```

```{r}
creators <- office_info%>%distinct(episode_name,director,writer)%>%
  separate_rows(writer,sep = ";")%>%
  pivot_longer(director:writer,names_to = "job",values_to = "name")%>%
  add_count(name)%>%filter(n>10)%>%mutate(count = 1)%>%
  distinct(episode_name,name,count)%>%
  pivot_wider(names_from = name,values_from = count, values_fill = 0)

creators
```


```{r}
rating_clean <- ratings_raw%>%transmute(season, episode,episode_name = title, rating = imdb_rating)%>%
    mutate(
    episode_name = str_to_lower(episode_name),
    episode_name = str_remove_all(episode_name, remove_regex),
    episode_name = str_trim(episode_name))

staff<-rating_clean%>%
    inner_join(creators)%>%
    inner_join(actors)

staff
```

```{r}
set.seed(1234)
staff_split<-initial_split(staff,strata = season)
staff_train <- training(staff_split)
staff_test <- testing(staff_split)

set.seed(123)
staff_boot<-bootstraps(staff_train, strata = season)
```

```{r}
staff_recipe<-recipe(rating~., data = staff_train)%>%
  update_role(episode_name, new_role = "ID")%>%
  step_zv(all_predictors())%>%
  step_corr(all_predictors())%>%
  step_normalize(all_predictors())

prep(staff_recipe)%>%juice()
```


```{r}
library(vip)
set.seed(2345)

lasso_model <- linear_reg(penalty = 0.1, mixture = 1)%>%
    set_engine("glmnet")

staff_wf<-workflow()%>%
  add_recipe(staff_recipe)%>%
  add_model(lasso_model)

staff_wf%>%fit(staff_train)%>%pull_workflow_fit()%>%
  tidy()
```


Now we are going to tune the penalty parameter.
```{r,message=FALSE}
tune_model <- linear_reg(penalty = tune())%>%set_engine("glmnet")

lambda_grid <- grid_regular(penalty(), levels = 50)

tune_grid<-tune_grid(workflow()%>%add_recipe(staff_recipe)%>%add_model(tune_model),
          resamples = staff_boot,
          grid = lambda_grid)
```

```{r}
tune_grid%>%collect_metrics()
```

```{r}
tune_grid%>%collect_metrics()%>%
    ggplot(aes(x = penalty, y = mean, color = .metric))+
    geom_point()+
    geom_line()+facet_wrap(~.metric,scales = "free",ncol = 1)+scale_x_log10()
```
```{r}
best_penalty<-tune_grid%>%select_best("rmse",maximize = FALSE)
best_penalty
```

```{r}
final_lasso<-finalize_workflow(workflow()%>%add_recipe(staff_recipe)%>%add_model(tune_model),
               best_penalty)
final_lasso
```

```{r}
final_lasso%>%fit(staff_train)%>%pull_workflow_fit()%>%vi(lamda = best_penalty$penalty)%>%
  mutate(Importance = case_when(Sign == "POS"~Importance,
                                       TRUE~(-1)*Importance))%>%
  ggplot(aes(x = Importance, y = reorder(Variable, Importance), color = Sign))+
  geom_point(size = 2)+
  geom_segment(aes(x = 0, xend = Importance, y = Variable, yend = Variable),size = 1.5)

```

```{r}
final_lasso%>%last_fit(staff_split)%>%collect_metrics()
```




